
### 依赖环境

请确保你的开发环境中安装了以下工具和库：

- Python 3.8 或更高版本
- `pip` 包管理器
- FunASR、silero-vad、deepseek、edge-tts 所需的依赖库

### 安装步骤



1. 安装所需依赖：

    
    pip install -r requirements.txt
    

2. 配置环境变量：

     - 打开config/config.yaml 配置ASR LLM等相关配置
     - 下载SenseVoiceSmall到目录models/SenseVoiceSmall [SenseVoiceSmall下载地址](https://huggingface.co/FunAudioLLM/SenseVoiceSmall/tree/main)
     - 去deepseek官网，获取配置api_key，[deepseek获取api_key](https://platform.deepseek.com/api_keys)，当然也可以配置openai、qwen、gemini、01yi等其他模型

3. 运行项目：

     
    cd server
    python server.py # 启动后端服务，也可不执行这一步
    
    
    
    python main.py
    

## 使用说明

1. 启动应用后，系统会等待语音输入。
2. 通过 FunASR 将用户语音转为文本。
3. silero-vad 进行语音活动检测，确保只处理有效语音。
4. deepseek 处理文本输入，并生成智能回复。
5. edge-tts, ChatTTS, MacOs say 将生成的文本转换为语音，并播放给用户。


# 百聆机器人技术文档



## 目录
1. [系统架构](#系统架构)
2. [核心模块](#核心模块)
3. [消息推送机制](#消息推送机制)
4. [接口说明](#接口说明)
5. [功能描述](#功能描述)
6. [配置与运行](#配置与运行)
7. [错误处理与日志](#错误处理与日志)
8. [示例与使用](#示例与使用)

---

## 系统架构
系统架构主要包括以下几个模块：
- **录音模块（Recorder）**：负责从麦克风捕获音频数据。
- **语音识别模块（ASR）**：将音频数据转换为文本。
- **自然语言处理模块（LLM）**：处理用户输入的文本并生成响应。
- **语音合成模块（TTS）**：将文本转换为语音。
- **语音活动检测模块（VAD）**：检测语音的开始和结束。
- **任务管理模块（TaskManager）**：管理后台任务。
- **对话管理模块（Dialogue）**：管理多轮对话的上下文。
- **面试会话模块（InterviewSession）**：管理面试会话，生成个性化问题。
- **消息推送模块（push2web）**：将对话消息（文本、语音、图片）推送到本地 Web 服务器。

---

## 核心模块

### 1. 录音模块（Recorder）
- **功能**：从麦克风捕获音频数据，并将其放入音频队列中。
- **接口**：
  - `start_recording(audio_queue)`：开始录音，并将音频数据放入指定的队列中。
  - `stop_recording()`：停止录音。

### 2. 语音识别模块（ASR）
- **功能**：将音频数据转换为文本。
- **接口**：
  - `recognizer(voice_data)`：将音频数据转换为文本。

### 3. 自然语言处理模块（LLM）
- **功能**：处理用户输入的文本并生成响应。
- **接口**：
  - `generate_next_action(query)`：根据用户输入生成下一步动作（如回复文本、生成图片等）。

### 4. 语音合成模块（TTS）
- **功能**：将文本转换为语音。
- **接口**：
  - `to_tts(text)`：将文本转换为语音文件。

### 5. 语音活动检测模块（VAD）
- **功能**：检测语音的开始和结束。
- **接口**：
  - `is_vad(data)`：检测音频数据中是否包含语音活动。

### 6. 任务管理模块（TaskManager）
- **功能**：管理后台任务。
- **接口**：
  - `add_task(task)`：添加任务到任务队列。
  - `get_task()`：从任务队列中获取任务。

### 7. 对话管理模块（Dialogue）
- **功能**：管理多轮对话的上下文。
- **接口**：
  - `add_message(message)`：添加消息到对话上下文。
  - `get_messages()`：获取对话上下文中的所有消息。

### 8. 面试会话模块（InterviewSession）
- **功能**：管理面试会话，生成个性化问题。
- **接口**：
  - `initialize_agent(patient_info)`：初始化面试会话，生成个性化问题。
  - `get_initial_question()`：获取初始问题。

---

## 消息推送机制

### `push2web` 函数
- **功能**：将对话消息（文本、语音、图片）推送到本地 Web 服务器。
- **参数**：
  - `payload (dict)`：消息负载，包含消息类型和内容。
  - `web_url (str)`：Web 服务器的基本 URL，默认为 `http://127.0.0.1:5000`。
- **支持的消息类型**：
  - **文本消息**：将文本内容推送到 Web 服务器的 `/add_message` 接口。
  - **语音消息**：上传语音文件到 Web 服务器的 `/upload_audio` 接口，并将返回的 URL 推送到 `/add_message` 接口。
  - **图片消息**：上传图片文件到 Web 服务器的 `/upload_image` 接口，并将返回的 URL 推送到 `/add_message` 接口。
- **错误处理**：
  - 如果文件不存在或上传失败，会记录错误日志。

---

## 接口说明

### 1. `Robot` 类
- **功能**：百聆机器人的主类，负责协调各个模块的工作。
- **接口**：
  - `__init__(config_file)`：初始化机器人，读取配置文件并初始化各个模块。
  - `listen_dialogue(callback)`：设置回调函数，用于处理对话中的消息。
  - `run()`：启动机器人，开始录音和处理语音数据。
  - `shutdown()`：关闭机器人，释放资源。
  - `interrupt_playback()`：中断当前的语音播放。
  - `start_recording_and_vad()`：开始录音和语音活动检测。
  - `chat(query)`：处理用户输入的文本并生成响应。

### 2. `InterviewSession` 类
- **功能**：管理面试会话，生成个性化问题。
- **接口**：
  - `__init__()`：初始化面试会话。
  - `initialize_agent(patient_info)`：初始化面试会话，生成个性化问题。
  - `get_initial_question()`：获取初始问题。

---

## 功能描述

### 1. 实时语音交互
百聆机器人能够通过麦克风实时捕获用户的语音输入，并通过语音识别模块将其转换为文本。然后，自然语言处理模块会生成响应，并通过语音合成模块将响应转换为语音播放给用户。

### 2. 多轮对话管理
机器人能够管理多轮对话的上下文，确保对话的连贯性。通过对话管理模块，机器人可以记住之前的对话内容，并根据上下文生成合适的响应。

### 3. 任务管理
机器人支持后台任务的管理。通过任务管理模块，机器人可以在空闲时处理后台任务，如播放预先录制的语音或执行其他任务。

### 4. 个性化问题生成
在面试场景中，机器人可以根据用户提供的信息生成个性化的问题。通过面试会话模块，机器人能够生成与用户背景相关的问题，并进行多轮对话。

### 5. 打断功能
机器人支持打断功能。当用户正在说话时，机器人可以中断当前的语音播放，优先处理用户的输入。

### 6. 消息推送
机器人支持将对话消息（文本、语音、图片）推送到本地 Web 服务器，便于前端展示和用户交互。

---

## 配置与运行

### 1. 配置文件
百聆机器人的配置文件采用 JSON 格式，包含各个模块的配置参数。配置文件的主要内容包括：
- **Recorder**：录音模块的配置。
- **ASR**：语音识别模块的配置。
- **LLM**：自然语言处理模块的配置。
- **TTS**：语音合成模块的配置。
- **VAD**：语音活动检测模块的配置。
- **TaskManager**：任务管理模块的配置。




